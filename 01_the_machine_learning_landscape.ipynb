{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "**Machine Learning** is the science (and art) of programming computers so they can learn from data.\n",
    "\n",
    "Applying ML techniques to dig into large amounts of data can help discover patterns that were not immediately apparent. This is called **Data Mining**.\n",
    "\n",
    "To summarize, ML is greate for:\n",
    "- problems for which existing solutions require a lot of hand-tuning or long lists of rules: one ML algorithm can often simplify code and perform better.\n",
    "- Complex probelms for which there is no good solution at all using a traditonal approach: the best ML techniques can find a solution.\n",
    "- Flucuating environments:a ML system can adapt to new data.\n",
    "- Getting insights about complex problems and large amounts of data.\n",
    "\n",
    "# Types of Machine Learning\n",
    "It is uesful to calssify them in broad categories based on:\n",
    "- Whether or not they are trained with human supervision(supervised, unsupervised, semisupervised, and Reinforment Learning)\n",
    "- Whether or not they can learn incrementally on the fly(online versus batch learning)\n",
    "- Whether whty work by simply comparing new data points to known data points, or instead detect patterns in the training data and build a predictive model, much like scientists do(instance-based versus model-based learning)\n",
    "\n",
    "## supervised learning algorithms\n",
    "- k-Nearest Neighbors\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "- Decision Trees and Random Forests\n",
    "- Neural networks\n",
    "\n",
    "## unsupervised learning\n",
    "- Clustering\n",
    "    - k-Means\n",
    "    - Hierarchical Cluster Analysis(HCA)\n",
    "    - Expectation Maximization\n",
    "- Visualization and dimensionality reduction\n",
    "    - Pricipal Componet Analysis(PCA)\n",
    "    - Kernel PCA\n",
    "    - Locally-Linear Embedding(LLE)\n",
    "    - t-distributed Stochatic Neighbor Embeddings(t-SNE)\n",
    "- Assciation rule learning(digging into large amounts of data and discover interesting relations between attributes.)\n",
    "    - Apriori\n",
    "    - Eclat\n",
    "    \n",
    "It is often a good idea to try to reduce the dimension of your training data using dimensionality reduction algorithm before you feed it to another ML algorithm. It will run much faster and sometimes perform better.\n",
    "\n",
    "## Semisupervised learning\n",
    "dealing with partially labeled training data, usually a lot of unlabeled data and a little bit of labeled data.\n",
    "\n",
    "## Reinforcement Learning\n",
    "Reinforcement Learning is a very different BEAST. The learning system, called an *agent* in this context, can observe the environment, select and perform actions, and get *reward* in return(or *penalties* in the form of negative rewards)\n",
    "\n",
    "## Batch and online Learning\n",
    "### Batch learning\n",
    "The system is **incapable** of learning incrementally: it must be trained using all the available data. This will generally take a lot of time and computing resources, so it is typically done offline. **It just applies what it has learned.**\n",
    "\n",
    "If you want a batch learning system to know about new data, you need to replace the old system with a new trained system.\n",
    "### Online learning(Incremental learning)\n",
    "In online learning, you train the systemn incrementally by feeding it data instances sequentially, either individually or by small called **mini-batches**. Each learning step is fast and cheap.\n",
    "\n",
    "One important parameter of online learning systems is how fast they should adapt to changing data. This is called **learning rate**.\n",
    "\n",
    "One big challenge with online learning is that **if bad data is fed to the system, the system's performance will gradually decline.**\n",
    "\n",
    "## Instance-based Versus Model-based Learning\n",
    "### instance-based learning\n",
    "The system learns the examples by heart, then generailzes to new cases using a similarity measure.\n",
    "\n",
    "### model-based learning\n",
    "Another way to generalize from a set of examples is to build a model of these examples, then use that model to make *predicitons*.\n",
    "\n",
    "*Example 1-1. Training and running a linear model using Scikit-Learn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "oecd_bli = pd.read_csv('datasets/lifesat/oecd_bli_2015.csv',thousands=',')\n",
    "gdp_per_capita = pd.read_csv('datasets/lifesat/gdp_per_capita.csv',thousands=',',delimiter='\\t',encoding='latin1', na_values=\"n/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Country</th>\n",
       "      <th>INDICATOR</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>MEASURE</th>\n",
       "      <th>Measure</th>\n",
       "      <th>INEQUALITY</th>\n",
       "      <th>Inequality</th>\n",
       "      <th>Unit Code</th>\n",
       "      <th>Unit</th>\n",
       "      <th>PowerCode Code</th>\n",
       "      <th>PowerCode</th>\n",
       "      <th>Reference Period Code</th>\n",
       "      <th>Reference Period</th>\n",
       "      <th>Value</th>\n",
       "      <th>Flag Codes</th>\n",
       "      <th>Flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>HO_BASE</td>\n",
       "      <td>Dwellings without basic facilities</td>\n",
       "      <td>L</td>\n",
       "      <td>Value</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Total</td>\n",
       "      <td>PC</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>0</td>\n",
       "      <td>units</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>E</td>\n",
       "      <td>Estimated value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>HO_BASE</td>\n",
       "      <td>Dwellings without basic facilities</td>\n",
       "      <td>L</td>\n",
       "      <td>Value</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Total</td>\n",
       "      <td>PC</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>0</td>\n",
       "      <td>units</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEL</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>HO_BASE</td>\n",
       "      <td>Dwellings without basic facilities</td>\n",
       "      <td>L</td>\n",
       "      <td>Value</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Total</td>\n",
       "      <td>PC</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>0</td>\n",
       "      <td>units</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>HO_BASE</td>\n",
       "      <td>Dwellings without basic facilities</td>\n",
       "      <td>L</td>\n",
       "      <td>Value</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Total</td>\n",
       "      <td>PC</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>0</td>\n",
       "      <td>units</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CZE</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>HO_BASE</td>\n",
       "      <td>Dwellings without basic facilities</td>\n",
       "      <td>L</td>\n",
       "      <td>Value</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Total</td>\n",
       "      <td>PC</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>0</td>\n",
       "      <td>units</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCATION         Country INDICATOR                           Indicator  \\\n",
       "0      AUS       Australia   HO_BASE  Dwellings without basic facilities   \n",
       "1      AUT         Austria   HO_BASE  Dwellings without basic facilities   \n",
       "2      BEL         Belgium   HO_BASE  Dwellings without basic facilities   \n",
       "3      CAN          Canada   HO_BASE  Dwellings without basic facilities   \n",
       "4      CZE  Czech Republic   HO_BASE  Dwellings without basic facilities   \n",
       "\n",
       "  MEASURE Measure INEQUALITY Inequality Unit Code        Unit  PowerCode Code  \\\n",
       "0       L   Value        TOT      Total        PC  Percentage               0   \n",
       "1       L   Value        TOT      Total        PC  Percentage               0   \n",
       "2       L   Value        TOT      Total        PC  Percentage               0   \n",
       "3       L   Value        TOT      Total        PC  Percentage               0   \n",
       "4       L   Value        TOT      Total        PC  Percentage               0   \n",
       "\n",
       "  PowerCode  Reference Period Code  Reference Period  Value Flag Codes  \\\n",
       "0     units                    NaN               NaN    1.1          E   \n",
       "1     units                    NaN               NaN    1.0        NaN   \n",
       "2     units                    NaN               NaN    2.0        NaN   \n",
       "3     units                    NaN               NaN    0.2        NaN   \n",
       "4     units                    NaN               NaN    0.9        NaN   \n",
       "\n",
       "             Flags  \n",
       "0  Estimated value  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd_bli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Subject Descriptor</th>\n",
       "      <th>Units</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Country/Series-specific Notes</th>\n",
       "      <th>2015</th>\n",
       "      <th>Estimates Start After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>599.994</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>3995.383</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>4318.135</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>4100.315</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>14414.302</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Country                                 Subject Descriptor  \\\n",
       "0          Afghanistan  Gross domestic product per capita, current prices   \n",
       "1              Albania  Gross domestic product per capita, current prices   \n",
       "2              Algeria  Gross domestic product per capita, current prices   \n",
       "3               Angola  Gross domestic product per capita, current prices   \n",
       "4  Antigua and Barbuda  Gross domestic product per capita, current prices   \n",
       "\n",
       "          Units  Scale                      Country/Series-specific Notes  \\\n",
       "0  U.S. dollars  Units  See notes for:  Gross domestic product, curren...   \n",
       "1  U.S. dollars  Units  See notes for:  Gross domestic product, curren...   \n",
       "2  U.S. dollars  Units  See notes for:  Gross domestic product, curren...   \n",
       "3  U.S. dollars  Units  See notes for:  Gross domestic product, curren...   \n",
       "4  U.S. dollars  Units  See notes for:  Gross domestic product, curren...   \n",
       "\n",
       "        2015  Estimates Start After  \n",
       "0    599.994                 2013.0  \n",
       "1   3995.383                 2010.0  \n",
       "2   4318.135                 2014.0  \n",
       "3   4100.315                 2014.0  \n",
       "4  14414.302                 2011.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_per_capita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                                  left_index=True, right_index=True)\n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[country_stats[\"GDP per capita\"]]\n",
    "y = np.c_[country_stats['Life satisfaction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c9a830518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visiualize the data\n",
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y=\"Life satisfaction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a linear model\n",
    "from sklearn import linear_model\n",
    "lin_reg_model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "lin_reg_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.96242338]]\n"
     ]
    }
   ],
   "source": [
    "# Make a predition for Cyprus\n",
    "X_new = [[22587]]  # Cyprus's GDP per capita\n",
    "print(lin_reg_model.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Challenges of Machine Learning\n",
    "## Insufficient Quantity of trainingData\n",
    "**这里要有图片！!!**\n",
    "\n",
    "## Nonrepresentative Training Data\n",
    "**In order to generalize well, it is crucial that your training data be representative of the new cases you want to generalize to.**\n",
    "- sampling noise\n",
    "- sampling bias\n",
    "\n",
    "## Poor-Quality Data\n",
    "It is often well worth the effort to spend time cleaning up your training data. The truth is, most data scientists spend a significant part of their time doing that.\n",
    "\n",
    "## Irrelevant Features\n",
    "**Garbage in, garbage out**\n",
    "\n",
    "A critical part of the success of a Machine Learning pproject is coming up with a good set of features to train on. This process, called **feature engineering**, involves:\n",
    "- **feature selection**: selecting the most useful features to train on among existing features.\n",
    "- **Feature extraction**: combining existing features to preduce a more useful one.\n",
    "- Creating new features by gathering new data.\n",
    "\n",
    "## Overfitting the Training data\n",
    "It means that the model performs well on the training data, but it does not generalize well.\n",
    "\n",
    "### Possibles solutions\n",
    "- To simplify the model by selecting one with fewer parameter, by reducing the number of attributes in the training data or by constraining the model.\n",
    "- To gather more training data\n",
    "- To reduce the noise in the training data.\n",
    "\n",
    "Constraining a model to make it simpler and reduce the risk of overfitting is called **regularization**. For example, the linear model we defined earlier has two parameters, $\\theta_0$ and $\\theta_1$. This gives the learning algorithm two *degrees of freedom* to adapt the model to the training data: it can tweak(调整）both the height($\\theta_0$) and the slope($\\theta_1$) of the line. If we forced $\\theta_0 = 0$, the algorethm would have only one degree of freedom and would have a much harder time fitting the data properly: all it could do is move the line up or down to get as close as possible to the training instances, so it would end up around the mean. A very simple model indeed! If we allow the algorithm to modify $\\theta_1$ but we force it to keep it small, then the learning algorithm will effectively have somewhere in betweent one and two degrees of freedom. **It will produce a simpler model than with two degree of freedom, but more complex than with just one.**\n",
    "**这里要有图片！1-23!!**\n",
    "\n",
    "The amount of regularization to apply during learning can be contraolled by a **hyperparameter**. A hyperparameter is a parameter of a learning algorithm(not of the model). It must be set prior to training and remains constant during training. **Tuning hyperparameters is an important part of building a Machine Learning system**.\n",
    "\n",
    "## Underfitting the Training data\n",
    "### Main options to fix that:\n",
    "- Selecting a more powerful model, with more parameters\n",
    "- Feeding better features to the learning algorithm.(feature engneering)\n",
    "- Reducing the constraints on the model.\n",
    "\n",
    "## Testing and Validating\n",
    "Split your data into two sets: the **training set** and the **test set**. Train your model using the training set and test it using the test set. The error rate on new cases is called the **generalization error**. This value tells you how well your model will perform on instances it has never seen before. \n",
    "\n",
    "If the training error is low but the generalization error is high, it means that your model is **overfitting** the training data.\n",
    "\n",
    "### how do you choose the value of regularization hyperparameter?\n",
    "One option is to train 100 models using 100 different values for this hyperparameter. Suppose you find the best hyperparameter value, so you launch this model into production, but unfortunately it does not perform as well as expected. \n",
    "\n",
    "The problem is that you measured the generalization error multiple times on the test set, and you adapted the model and hyperparameters to produce the best model *for that set*. This means that the model is unlikely to perform as well as on new data. \n",
    "\n",
    "**A common solution to shis problem is to have a second holdout set called Validation set**. You train models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validataion set, and when you are happy with your model you run a single final test against the test set to get an estimate of the generalization error.\n",
    "\n",
    "To avoid \"wasting\" to much training data in validation sets, a common technique is to use **cross validation**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
