{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoushands or even millions of features not only make training extremely slow, also make it harder to find a good solution, this is called **the curse of dimensionality**.\n",
    "\n",
    "# Main content\n",
    "- the curse of dimensionality\n",
    "- know high-dimensional space\n",
    "- projection and Manifold learning\n",
    "- PCA, Kernel PCA, LLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Curse of Dimensionality\n",
    "The more dimensions the training set has, the greater the risk of overfitting it. In theory, one solution to the curse of dimensionality could be to increase the size of training set to reach a sufficient density of training instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Approaches for Dimensionality Reduction\n",
    "## Projection\n",
    "Training instances are not spread out uniformly across all dimensions. Many features are almost constant, while others are highly correlated. As a result, all training instances actually lie within a much lower-dimensional space. See an example.\n",
    "\n",
    "![8](images/8-2.png)\n",
    "\n",
    "![8](images/8-3.png)\n",
    "\n",
    "![8](images/8-4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
