{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Your First Graph and Running It in a Session\n",
    "\n",
    "![9](images/9-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y +y +2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing to understand is that this code does not actually perform any computation. It just creates a computation graph.\n",
    "\n",
    "To evaluate this graph, you need to open a TensorFlow session and use it to initialize the variables and evaluate f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "\n",
    "sess.close() # free up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to repeat `sess.run()` all the time is a bit cumbersome(麻烦的), but fortunately there is a better way:\n",
    "\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "    x.initializer().run()\n",
    "    y.initializer().run()\n",
    "    result = f.eval()\n",
    "```\n",
    "\n",
    "**Error:'Operation' object is not callable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `with` block, the session is set as the default session.\n",
    "\n",
    "A TensorFlow program is typically split into two parts:\n",
    "1. **Construction phase**: builds a computation graph representing the ML model and the computations required to train it.\n",
    "2. **Execution phase**: runs a lood that evaluates a training setp repeatedly, gradually imporving the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Graphs\n",
    "Any node you create is automatically to the default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases this is fine, but sometimes you may want to manage multiple independent graphs. You can do this by creating a new `Graph` and temporarily making it the default fraph inside a `with` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In jupyter, it is common to run the same commands more than once. You may end up with a default graph containing many duplicate nodes. One solution is to restart the kernel while another solution is to just reset the default graph by running `tf.reset_default_graph()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifecycle of a Node Value\n",
    "TensorFlow automatically determines the set of nodes that is depends on and it evaluates these nodes first. For example: \n",
    "- First, this code defines a very simple graph. \n",
    "- Then it starts a session and runs  the graph to evaluate y: TensorFlow automatically detects that y depends on w, which depends on x, so it first evaluates w, then x, then y, and return the value of y.\n",
    "- Finally, the code runs the graph to evaluate z.\n",
    "\n",
    "**It is important to note that it will not reuse the result of the previous evaluation of w and x. In short, the code evaluates w and x twice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w+2\n",
    "y = x+5\n",
    "z = x*3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All node values are dropped between graph runs, except variable values, which are maintained by the session across graph runs. A variable starts its life when its initializer is run, and it ends when the session is closed.**\n",
    "\n",
    "to Evaluate y and z efficiently, without evaluating w and x twice as in the previous code, ask TensorFlow to evaluate boty y and z in just one graph run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val,z_val = sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In single-process TensorFlow, each session would have its own copy of every variable. In distributed TensorFlow, variable state is stored on the servers, not in the sessions, so multiple sessions can share the same varibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow\n",
    "TensorFlow operations(*ops* for short) can take any number of inputs and produce any number of outputs. **Constants and variables** take no input(they are called *source ops*). The inputs and outputs are multidimensional arrays, called *tensors*. In the python API tensors are simply represented by Numpy ndarrays. They typically contain floats, but you can also use them to carry strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.71851807e+01]\n",
      " [  4.36337471e-01]\n",
      " [  9.39523336e-03]\n",
      " [ -1.07113101e-01]\n",
      " [  6.44792199e-01]\n",
      " [ -4.03380000e-06]\n",
      " [ -3.78137082e-03]\n",
      " [ -4.23484027e-01]\n",
      " [ -4.37219113e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent\n",
    "**When using Gradient Descent, it is important to first bormalize the input feature vectors, or else trining may be much slower.**\n",
    "\n",
    "\n",
    "## Manually Computing the Gradient\n",
    "- `random_uniform()` function creates a node in the graph that will generate a tensor containing random values.\n",
    "- `assign()` function creates a node that will assign a new value to a variable.\n",
    "- The main loop executes the training step over and over again(`n_epochs` times) and every 100 iterations it prints out the current Mean Squared Error(mse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 3.40109\n",
      "Epoch 100 MSE= 3.40109\n",
      "Epoch 200 MSE= 3.40109\n",
      "Epoch 300 MSE= 3.40109\n",
      "Epoch 400 MSE= 3.40109\n",
      "Epoch 500 MSE= 3.40109\n",
      "Epoch 600 MSE= 3.40109\n",
      "Epoch 700 MSE= 3.40109\n",
      "Epoch 800 MSE= 3.40109\n",
      "Epoch 900 MSE= 3.40109\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled_housing_data_plus_bias = min_max_scaler.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0,1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name= 'predictions')\n",
    "error = y_pred -y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta-learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 ==0:\n",
    "            print('Epoch', epoch, 'MSE=', mse.eval())\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
